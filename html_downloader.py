# html_downloader.py
import os
import requests
from urllib.parse import urlparse
from tqdm import tqdm

SAVE_DIR = "downloaded_html"
os.makedirs(SAVE_DIR, exist_ok=True)

with open("all_links.txt", "r", encoding="utf-8") as f:
    urls = [line.strip() for line in f if line.strip()]

for url in tqdm(urls, desc="ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘"):
    try:
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            parsed = urlparse(url)
            filename = parsed.path.strip("/").replace("/", "_")
            if not filename:
                filename = "index"
            full_path = os.path.join(SAVE_DIR, f"{filename}.html")
            with open(full_path, "w", encoding="utf-8") as out:
                out.write(r.text)
        else:
            print(f"[!] ì‹¤íŒ¨: {url} ({r.status_code})")
    except Exception as e:
        print(f"[!] ì—ëŸ¬: {url} ({e})")

print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {len(os.listdir(SAVE_DIR))}ê°œ HTML â†’ {SAVE_DIR}/")
